import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
import joblib  # ëª¨ë¸ ì €ì¥ ë° ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# ë°ì´í„° ë¡œë“œ
data_path = "Test_Training_Data.csv"
data = pd.read_csv(data_path)

# ë‚ ì§œ ë³€í™˜
date_cols = ['completed_at', 'session_start', 'session_end', 'start_time', 'end_time']
for col in date_cols:
    data[col] = pd.to_datetime(data[col], errors='coerce')

# ì„¸ì…˜ ì§€ì† ì‹œê°„ ê³„ì‚° (ë¶„ ë‹¨ìœ„)
data['session_duration'] = (data['session_end'] - data['session_start']).dt.total_seconds() / 60

# í™œë™ ë¹ˆë„ ê³„ì‚° (ì¼ì¼ ë¯¸ì…˜ ìˆ˜í–‰ íšŸìˆ˜)
activity_counts = data.groupby(['user_id', 'date'])['activity_type_y'].count().reset_index()
activity_counts.rename(columns={'activity_type_y': 'daily_activity_count'}, inplace=True)
data = pd.merge(data, activity_counts, on=['user_id', 'date'], how='left')

# ì´ ë¯¸ì…˜ ìˆ˜í–‰ íšŸìˆ˜ ê³„ì‚°
total_mission_count = data.groupby('user_id')['mission_id'].count().reset_index()
total_mission_count.rename(columns={'mission_id': 'total_mission_count'}, inplace=True)
data = pd.merge(data, total_mission_count, on='user_id', how='left')

# ë¯¸ì…˜ë³„ íƒ„ì†Œ ì ˆê°ëŸ‰ ë§¤í•‘ ìˆ˜ì •
carbon_reduction_map = {
    'í…€ë¸”ëŸ¬ ì‚¬ìš©í•˜ê¸°': 0.05,
    '3000ê±¸ìŒ ì¤„ì´ê¸°': 0.2,
    'ì „ì ì˜ìˆ˜ì¦ ì—…ë¡œë“œ ë¯¸ì…˜': 0.1
}
data['carbon_reduction'] = data['name_x'].map(carbon_reduction_map)

# ì‚¬ìš©ìë³„ ì´ íƒ„ì†Œ ì ˆê°ëŸ‰ ê³„ì‚°
weekly_carbon_reduction = data.groupby('user_id')['carbon_reduction'].sum().reset_index()
weekly_carbon_reduction.rename(columns={'carbon_reduction': 'total_weekly_carbon_reduction'}, inplace=True)
data = pd.merge(data, weekly_carbon_reduction, on='user_id', how='left')

# Xì™€ y ìƒì„±
X = data[['total_mission_count']]
y = data['total_weekly_carbon_reduction']

# ë°ì´í„° ë¶„í•  ë° ëª¨ë¸ í•™ìŠµ
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
rf_model = RandomForestRegressor(n_estimators=30, max_depth=7, min_samples_split=10, random_state=42)
rf_model.fit(X_train, y_train)

# ëª¨ë¸ ì €ì¥
joblib.dump(rf_model, 'rf_model.joblib')
print("ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")

# ì˜ˆì¸¡ ìˆ˜í–‰
data['predicted_carbon_reduction'] = rf_model.predict(X)

# ì‚¬ìš©ìë³„ í™˜ê²½ ê¸°ì—¬ë„ ìˆœìœ„ ê³„ì‚°
data['percentile_rank'] = data['predicted_carbon_reduction'].rank(pct=True) * 100

def categorize_user(percentile, total_missions):
    if total_missions < 7:  # Assuming a week's data collection
        return "ë§Œë‚˜ê²Œ ë˜ì–´ ë°˜ê°€ì›Œìš”, ì•„ì§ ë” ë§ì€ ìŠ¤í…ì´ í•„ìš”í•´ìš”!"
    elif percentile >= 75:
        return "ìƒìœ„ 25% - í›Œë¥­í•œ ì—ì½”ìŠ¤í…ëŸ¬! ğŸŒ±"
    elif percentile >= 50:
        return "ìŠ¤íƒ ë‹¤ë“œ ì—ì½”ìŠ¤í…ëŸ¬ - ì¢‹ì€ ì°¸ì—¬ë¥¼ ë³´ì´ê³  ìˆë„¤ìš”, ê·¸ëŸ¬ë‚˜ ë” ë‚˜ì•„ê°ˆ ìˆ˜ ìˆì–´ìš”! ğŸš€"
    else:
        return "í•˜ìœ„ 50% - ì‘ì€ ì‹¤ì²œìœ¼ë¡œ ë” í° ë³€í™”ë¥¼! ğŸŒ"

data['eco_category'] = data.apply(lambda x: categorize_user(x['percentile_rank'], x['total_mission_count']), axis=1)

# ê²°ê³¼ CSV íŒŒì¼ ì €ì¥
data.to_csv("final_user_eco_analysis.csv", index=False, encoding="utf-8-sig")

print("âœ… ëª¨ë¸ ì‹¤í–‰ ì™„ë£Œ! `final_user_eco_analysis.csv` íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
