from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional
import pandas as pd
import joblib
from datetime import datetime

# FastAPI ê°ì²´ ìƒì„±
app = FastAPI()

# í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model = joblib.load("rf_model.joblib")

# ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜ (ì…ë ¥ ì»¬ëŸ¼ ì „ì²´ í¬í•¨, ì (.) í•„ë“œ alias ì²˜ë¦¬)
class UserRecord(BaseModel):
    id_x: int
    user_id: int
    mission_id: int
    completed_at: str
    id_y: int
    name_x: str
    description: str
    carbon_reduction: float = 0.0
    name_y: str
    email: str
    created_at: str
    id_x_1: int = Field(..., alias="id_x.1")  # JSON: id_x.1
    timestamp: str
    activity_type_x: str
    page_id: Optional[str] = None
    button_id: Optional[str] = None
    id_y_1: int = Field(..., alias="id_y.1")  # JSON: id_y.1
    session_start: str
    session_end: str
    duration: str
    activity_type_y: str
    start_time: str
    end_time: str
    date: str

    class Config:
        allow_population_by_field_name = True  # aliasë¡œ ë§¤í•‘ í—ˆìš©

# ì˜ˆì¸¡ API
@app.post("/predict/")
async def predict(user_data: List[UserRecord]):
    try:
        # ì…ë ¥ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (alias ì´ë¦„ ì‚¬ìš©)
        df = pd.DataFrame([record.dict(by_alias=True) for record in user_data])

        # ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ íŒŒì‹±
        date_cols = ['completed_at', 'session_start', 'session_end', 'start_time', 'end_time']
        for col in date_cols:
            df[col] = pd.to_datetime(df[col], errors='coerce')

        # ì„¸ì…˜ ì‹œê°„ ê³„ì‚°
        df['session_duration'] = (df['session_end'] - df['session_start']).dt.total_seconds() / 60

        # ë‚ ì§œ ì»¬ëŸ¼ íŒŒì‹±
        df['date'] = pd.to_datetime(df['date'])

        # ì¼ì¼ í™œë™ íšŸìˆ˜ ê³„ì‚°
        activity_counts = df.groupby(['user_id', 'date'])['activity_type_y'].count().reset_index()
        activity_counts.rename(columns={'activity_type_y': 'daily_activity_count'}, inplace=True)
        df = pd.merge(df, activity_counts, on=['user_id', 'date'], how='left')

        # ì‚¬ìš©ìë³„ ì´ ë¯¸ì…˜ íšŸìˆ˜ ê³„ì‚°
        total_missions = df.groupby('user_id')['mission_id'].count().reset_index()
        total_missions.rename(columns={'mission_id': 'total_mission_count'}, inplace=True)
        df = pd.merge(df, total_missions, on='user_id', how='left')

        # ë¯¸ì…˜ ì´ë¦„ â†’ íƒ„ì†Œ ì ˆê°ëŸ‰ ë§¤í•‘
        carbon_reduction_map = {
            'í…€ë¸”ëŸ¬ ì‚¬ìš©í•˜ê¸°': 0.05,
            '3000ê±¸ìŒ ì¤„ì´ê¸°': 0.2,
            'ì „ì ì˜ìˆ˜ì¦ ì—…ë¡œë“œ ë¯¸ì…˜': 0.1
        }
        df['carbon_reduction'] = df['name_x'].map(carbon_reduction_map)

        # ì‚¬ìš©ìë³„ ì´ íƒ„ì†Œ ì ˆê°ëŸ‰ ê³„ì‚°
        weekly_cr = df.groupby('user_id')['carbon_reduction'].sum().reset_index()
        weekly_cr.rename(columns={'carbon_reduction': 'total_weekly_carbon_reduction'}, inplace=True)
        df = pd.merge(df, weekly_cr, on='user_id', how='left')

        # ëª¨ë¸ ì˜ˆì¸¡
        X = df[['total_mission_count']]
        df['predicted_carbon_reduction'] = model.predict(X)

        # ê¸°ì—¬ë„ í¼ì„¼íƒ€ì¼ ê³„ì‚°
        df['percentile_rank'] = df['predicted_carbon_reduction'].rank(pct=True) * 100

        # í™˜ê²½ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ í•¨ìˆ˜
        def categorize(percentile, total_missions):
            if total_missions < 7:
                return "ë§Œë‚˜ê²Œ ë˜ì–´ ë°˜ê°€ì›Œìš”, ì•„ì§ ë” ë§ì€ ìŠ¤í…ì´ í•„ìš”í•´ìš”!"
            elif percentile >= 75:
                return "ìƒìœ„ 25% - í›Œë¥­í•œ ì—ì½”ìŠ¤í…ëŸ¬! ğŸŒ±"
            elif percentile >= 50:
                return "ìŠ¤íƒ ë‹¤ë“œ ì—ì½”ìŠ¤í…ëŸ¬ - ì¢‹ì€ ì°¸ì—¬ë¥¼ ë³´ì´ê³  ìˆë„¤ìš”, ê·¸ëŸ¬ë‚˜ ë” ë‚˜ì•„ê°ˆ ìˆ˜ ìˆì–´ìš”! ğŸš€"
            else:
                return "í•˜ìœ„ 50% - ì‘ì€ ì‹¤ì²œìœ¼ë¡œ ë” í° ë³€í™”ë¥¼! ğŸŒ"

        df['eco_category'] = df.apply(lambda x: categorize(x['percentile_rank'], x['total_mission_count']), axis=1)

        # ê²°ê³¼ ë°˜í™˜ (JSON)
        result = df[[
            'user_id', 'total_mission_count', 'total_weekly_carbon_reduction',
            'predicted_carbon_reduction', 'percentile_rank', 'eco_category'
        ]]

        return result.to_dict(orient="records")

    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))
